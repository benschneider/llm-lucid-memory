[![Tests](https://img.shields.io/github/workflow/status/benschneider/llm-lucid-memory/Tests)]()

[![License](https://img.shields.io/github/license/benschneider/llm-lucid-memory)](LICENSE)

# ğŸ§  llm-lucid-memory

**Lucid Memory** is an open-source project aiming to enable small and medium LLMs to **reason beyond their context windows** â€” through modular memory digestion, structured storage, reflective retrieval, and chain-of-draft reasoning.

> **Imagine:** Your model thinking more like a brain, not just predicting the next token.

---

## ğŸŒŸ Why Lucid Memory?

- **Digest** knowledge offline into modular, logic-rich memory nodes
- **Store** memories flexibly (searchable by tags, keywords, and logic paths)
- **Reflectively retrieve** only relevant memories for a question
- **Draft answers** based on structured reasoning, not blind retrieval
- **Unlock huge knowledge bases** even with limited context models

---

## ğŸ“š Concept Overview

**The Problem:**  
- Small LLMs can't fit large codebases or document sets.
- Existing RAG (retrieval augmented generation) just crams context into prompts.
- LLMs need *structured*, *logical*, *reflective* memory systems.

**The Solution:**  
Lucid Memory introduces a lightweight brain architecture for LLMs:
- Preprocess (digest) large information offline.
- Save modular memories with summaries and reasoning paths.
- Reflectively retrieve and reason using only what matters.

---

## ğŸ”¥ Core Reasoning Flow

```plaintext
[DIGEST PHASE - offline]
Raw Knowledge -> Digestor -> MemoryNode -> MemoryGraph (saved)

[QUERY PHASE - online]
User Question -> ReflectiveRetriever -> Select Relevant Memories -> ChainOfDraftEngine -> Logical Answer



```



## ğŸ§ª Quick Start

Install dependencies: ``` pip install -r requirements.txt ```

Run tests: ``` pytest ```

Run a simple ingestion demo: ``` python -m examples.simple_digest_demo ```


## ğŸ§  Example Usage

Question:

â€œHow does the server start and accept secure connections?â€

Memory Retrieval:
	â€¢	Memory 1: Start server (open socket, bind port, accept requests)
	â€¢	Memory 2: Handle TLS (perform handshake, secure channel)

Drafted Answer:
	â€¢	Open socket
	â€¢	Bind port
	â€¢	Accept connection
	â€¢	Initiate TLS handshake
	â€¢	Proceed with secured HTTP handling


## ğŸŒ± What's Coming Next?

| Feature                               | Status    |
|:--------------------------------------|:----------|
| ChainOfDraftEngine (parallel reasoning chains) | ğŸ”œ Planned |
| MemoryNode versioning                 | ğŸ”œ Future  |
| Graph-based retrieval paths           | ğŸ”œ Future  |
| Sleep-time memory growth (dream ingestion) | ğŸ”œ Future  |
| Fine-tuning LLMs for memory reasoning  | ğŸ”œ Future  |

## ğŸ“œ License

Apache 2.0 â€” free for commercial and research use with attribution.

## âœ¨ Vision

We are building a modular reasoning brain for LLMs:
	â€¢	Digest structured memories
	â€¢	Reflectively retrieve knowledge
	â€¢	Reason flexibly beyond context limits
	â€¢	Grow smarter over time

Helping small models think big â€” the way real minds do. ğŸš€

## Project Structure

llm-lucid-memory/
â”œâ”€â”€ README.md          # Project overview
â”œâ”€â”€ LICENSE            # Apache 2.0 License
â”œâ”€â”€ lucid_memory/      # Core modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ digestor.py     # Digest raw input into MemoryNodes
â”‚   â”œâ”€â”€ memory_node.py  # Single knowledge atoms
â”‚   â”œâ”€â”€ memory_graph.py # In-memory brain managing MemoryNodes
â”‚   â”œâ”€â”€ retriever.py    # ReflectiveRetriever (smart retrieval)
â”‚   â””â”€â”€ chain_engine.py # ChainOfDraftEngine (planned)
â”œâ”€â”€ examples/          # Demos and pipelines
â”‚   â””â”€â”€ simple_digest_demo.py
â”œâ”€â”€ tests/             # Test suites for all modules
â”‚   â”œâ”€â”€ test_digestor.py
â”‚   â”œâ”€â”€ test_memory_graph.py
â”‚   â”œâ”€â”€ test_memory_node.py
â”‚   â””â”€â”€ test_retriever.py
â”œâ”€â”€ requirements.txt   # Lightweight requirements
â””â”€â”€ setup.py           # Optional pip packaging


