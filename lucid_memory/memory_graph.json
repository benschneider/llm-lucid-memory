{
  "file_codebase_analyzer_python_function_CodebaseAnalyzer__count_lines_6": {
    "id": "file_codebase_analyzer_python_function_CodebaseAnalyzer__count_lines_6",
    "raw": "    def _count_lines(self, file_path):\n        \"\"\"Count lines in a text file. // Contar líneas en un archivo de texto.\"\"\"\n        try:\n            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n                return sum(1 for _ in f)\n        except Exception:\n            return 0\n",
    "summary": "The function counts the number of lines present in a given text file.",
    "key_concepts": [
      "File handling",
      "Line counting function",
      "UTF-8 encoding",
      "Exception handling",
      "Return value",
      "Key Arguments/Claims: None specified. Core Terminology:",
      "Open file method",
      "Sum operation",
      "For loop iteration"
    ],
    "tags": [
      "file handling",
      "text processing",
      "exception management",
      "file reading",
      "utf-8 encoding",
      "python function",
      "error suppression",
      "unicode support"
    ],
    "sequence_index": 5,
    "parent_identifier": "CodebaseAnalyzer",
    "dependencies": [
      "file_path"
    ],
    "produced_outputs": [
      "file_count",
      "self.file_path"
    ],
    "follow_up_questions": [],
    "source": null
  },
  "file_codebase_analyzer_python_function_CodebaseAnalyzer__print_progress_4": {
    "id": "file_codebase_analyzer_python_function_CodebaseAnalyzer__print_progress_4",
    "raw": "    def _print_progress(self, current, total, prefix='', suffix=''):\n        \"\"\"Print a progress bar if in terminal. // Imprimir una barra de progreso si está en terminal.\"\"\"\n        if sys.stdout.isatty():\n            bar_length = 30\n            filled_length = int(round(bar_length * current / float(total)))\n            percents = round(100.0 * current / float(total), 1)\n            bar = '█' * filled_length + '-' * (bar_length - filled_length)\n            sys.stdout.write(f'\\r{prefix} |{bar}| {percents}% {suffix}')\n            sys.stdout.flush()\n            if current == total:\n                print()\n        else:\n            if current == total:\n                print(f\"{prefix} {current}/{total} complete\")\n",
    "summary": "Print a progress bar in the terminal when outputting to an interactive shell.",
    "key_concepts": [
      "Progress bar",
      "Terminal check (`sys.stdout.isatty`)",
      "Bar length calculation: 30 characters",
      "Filled portion of the progress bar based on current value",
      "Percentage completion display with one decimal place accuracy",
      "Dynamic output formatting using `print()`",
      "Flush standard output for immediate visibility in terminal"
    ],
    "tags": [
      "progress bar",
      "terminal output",
      "sys.stdout",
      "isatty",
      "flush",
      "completion",
      "percentage calculation",
      "progress tracking"
    ],
    "sequence_index": 3,
    "parent_identifier": "CodebaseAnalyzer",
    "dependencies": [
      "sys",
      "stdout",
      "import sys"
    ],
    "produced_outputs": [],
    "follow_up_questions": [],
    "source": null
  },
  "file_codebase_analyzer_python_function_CodebaseAnalyzer__print_status_3": {
    "id": "file_codebase_analyzer_python_function_CodebaseAnalyzer__print_status_3",
    "raw": "    def _print_status(self, message):\n        \"\"\"Print a status message with color if supported. // Imprimir un mensaje de estado con color si es compatible.\"\"\"\n        if sys.stdout.isatty():\n            print(f\"\\033[1;36m{message}\\033[0m\")\n        else:\n            print(message)\n",
    "summary": "The function prints colored status messages to the console when output is supported.",
    "key_concepts": [
      "_print_status method",
      "Status message printing",
      "Color support check",
      "sys.stdout.isatty()",
      "ANSI escape codes for colorization",
      "Terminal compatibility detection"
    ],
    "tags": [
      "sys.stdout",
      "isatty",
      "terminal",
      "escape sequence",
      "ANSI color code",
      "text output",
      "console message"
    ],
    "sequence_index": 2,
    "parent_identifier": "CodebaseAnalyzer",
    "dependencies": [
      "sys",
      "stdout"
    ],
    "produced_outputs": [],
    "follow_up_questions": [],
    "source": null
  },
  "file_codebase_analyzer_python_function_CodebaseAnalyzer__check_git_2": {
    "id": "file_codebase_analyzer_python_function_CodebaseAnalyzer__check_git_2",
    "raw": "    def _check_git(self):\n        \"\"\"Check if git is available and if the directory is a git repository. // Verificar si git está disponible y si el directorio es un repositorio git.\"\"\"\n        try:\n            subprocess.run([\"git\", \"--version\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)\n            subprocess.run([\"git\", \"rev-parse\", \"--is-inside-work-tree\"], \n                         stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)\n            return True\n        except (subprocess.SubprocessError, FileNotFoundError):\n            return False\n",
    "summary": "The function checks for the availability of git and whether a given directory is inside a Git repository.",
    "key_concepts": [
      "Check git availability",
      "Verify directory as a Git repository",
      "Use subprocess.run()",
      "Handle exceptions: SubprocessError, FileNotFoundError",
      "Return boolean value"
    ],
    "tags": [
      "python subprocess git repository error handling file not found exception command-line argument parsing system call exceptions directory traversal security audit package installation validation"
    ],
    "sequence_index": 1,
    "parent_identifier": "CodebaseAnalyzer",
    "dependencies": [
      "git",
      "FileNotFoundError",
      "subprocess.run",
      "subprocess.SubprocessError",
      "stdout",
      "stderr",
      "checkTrue",
      "isInsideWorkTree",
      "worktree"
    ],
    "produced_outputs": [
      "True",
      "False"
    ],
    "follow_up_questions": [],
    "source": null
  },
  "file_codebase_analyzer_python_function_CodebaseAnalyzer__should_ignore_5": {
    "id": "file_codebase_analyzer_python_function_CodebaseAnalyzer__should_ignore_5",
    "raw": "    def _should_ignore(self, path):\n        \"\"\"Check if path should be ignored. // Verificar si la ruta debe ser ignorada.\"\"\"\n        # Skip hidden paths, starting with . // [Omitir rutas ocultas que comienzan con .]\n        if os.path.basename(path).startswith('.') and os.path.basename(path) not in ['.', '..']:\n            return True\n            \n        # Skip ignored directories // Omitir directorios ignorados\n        for ignored in self.ignore_dirs:\n            if f\"/{ignored}/\" in f\"{path}/\" or path.endswith(f\"/{ignored}\"):\n                return True\n        \n        # Skip ignored files // Omitir archivos ignorados\n        if os.path.isfile(path) and os.path.basename(path) in self.ignore_files:\n            return True\n            \n        return False\n",
    "summary": "The function determines whether a given file or directory path should be disregarded based on predefined criteria.",
    "key_concepts": [
      "Check path ignore criteria",
      "Hidden paths check: starts with '.",
      "Ignore directories list handling",
      "Ignored files identification",
      "Return boolean value based on checks"
    ],
    "tags": [
      "file handling",
      "path manipulation",
      "ignore logic",
      "directory traversal",
      "python os module",
      "string comparison",
      "file system navigation"
    ],
    "sequence_index": 4,
    "parent_identifier": "CodebaseAnalyzer",
    "dependencies": [
      "os.path",
      "self.ignore_dirs",
      "self.ignore_files"
    ],
    "produced_outputs": [
      "self.ignore_dirs",
      "self.ignore_files"
    ],
    "follow_up_questions": [],
    "source": null
  },
  "file_codebase_analyzer_python_function_CodebaseAnalyzer__is_text_file_7": {
    "id": "file_codebase_analyzer_python_function_CodebaseAnalyzer__is_text_file_7",
    "raw": "    def _is_text_file(self, file_path):\n        \"\"\"Check if a file is text based on extension. // Verificar si un archivo es texto basado en su extensión.\"\"\"\n        _, ext = os.path.splitext(file_path.lower())\n        return ext in self.text_extensions\n",
    "summary": "The function checks whether the given file path corresponds to an extension associated with text files.",
    "key_concepts": [
      "file checking",
      "text detection by extension",
      "os.path module",
      "lowercase conversion",
      "extension matching",
      "TEXT/CODE SNIPPET:",
      "def _is_text_file(self, file_path):",
      "\"\"Check if a file is text based on extension. // Verificar si un archivo es texto basado en su extensión.\"\"",
      "_, ext = os.path.splitext(file_path.lower())",
      "return ext in self.text_extensions"
    ],
    "tags": [
      "file handling",
      "python",
      "os.path",
      "string manipulation",
      "function definition",
      "file extensions",
      "lowercasing",
      "text detection"
    ],
    "sequence_index": 6,
    "parent_identifier": "CodebaseAnalyzer",
    "dependencies": [
      "os",
      "self.text_extensions"
    ],
    "produced_outputs": [
      "ext",
      "self.text_extensions"
    ],
    "follow_up_questions": [],
    "source": null
  },
  "file_codebase_analyzer_python_function_CodebaseAnalyzer__get_file_info_8": {
    "id": "file_codebase_analyzer_python_function_CodebaseAnalyzer__get_file_info_8",
    "raw": "    def _get_file_info(self, file_path):\n        \"\"\"Get file information. // Obtener información del archivo.\"\"\"\n        stat = os.stat(file_path)\n        size = stat.st_size\n        mtime = stat.st_mtime\n        is_text = self._is_text_file(file_path)\n        lines = self._count_lines(file_path) if is_text else 0\n        \n        return {\n            'path': os.path.relpath(file_path, self.project_root),\n            'size': size,\n            'mtime': mtime,\n            'is_text': is_text,\n            'lines': lines\n        }\n",
    "summary": "The function retrieves and returns detailed information about a file.",
    "key_concepts": [
      "File information retrieval",
      "os.stat()",
      "file attributes: st_size, st_mtime",
      "Text detection (_is_text_file)",
      "Line counting (_count_lines)",
      "Path normalization (os.path.relpath())",
      "Project root reference",
      "KEY CONCEPTS/STEPS:",
      "_get_file_info function definition",
      "stat object usage for metadata extraction",
      "size attribute retrieval from os.stat()",
      "modification time (mtime) access via os.stat()",
      "Text file identification with _is_text_file method",
      "Line count determination through _count_lines if text file",
      "Path normalization using os.path.relpath() to project root directory"
    ],
    "tags": [
      "file_info",
      "python",
      "os.stat",
      "file_size",
      "modification_time",
      "text_file_check",
      "relative_path",
      "project_root",
      "line_count"
    ],
    "sequence_index": 7,
    "parent_identifier": "CodebaseAnalyzer",
    "dependencies": [
      "os.stat",
      "self._is_text_file",
      "self._count_lines",
      "self.project_root"
    ],
    "produced_outputs": [
      "file_info",
      "self.xyz",
      "project_root",
      "stat",
      "st_size",
      "st_mtime",
      "is_text_file",
      "_count_lines",
      "os.path.relpath",
      "size",
      "mtime",
      "is_text",
      "lines"
    ],
    "follow_up_questions": [],
    "source": null
  },
  "file_codebase_analyzer_python_function_CodebaseAnalyzer___init_1": {
    "id": "file_codebase_analyzer_python_function_CodebaseAnalyzer___init_1",
    "raw": "    def __init__(self):\n        self.output_dir = \"00_docs\"\n        self.ignore_dirs = [\".git\", \"node_modules\", \"__pycache__\", \"venv\", \".venv\", \"env\", \n                           \".env\", \"dist\", \"build\", \".idea\", \".vscode\"]\n        self.ignore_files = [\".gitignore\", \".DS_Store\", \"Thumbs.db\"]\n        self.text_extensions = [\".py\", \".js\", \".jsx\", \".ts\", \".tsx\", \".html\", \".css\", \".scss\", \n                              \".md\", \".txt\", \".json\", \".yaml\", \".yml\", \".xml\", \".csv\", \".sql\", \n                              \".c\", \".cpp\", \".h\", \".java\", \".rb\", \".php\", \".go\", \".rs\", \".swift\",\n                              \".kt\", \".scala\", \".sh\", \".ps1\", \".bat\", \".cmd\"]\n        self.total_files = 0\n        self.total_text_files = 0\n        self.project_root = os.getcwd()\n        self.has_git = self._check_git()\n        \n        # Language detection patterns // Patrones de detección de lenguajes\n        self.language_patterns = {\n            \"Python\": [\".py\"],\n            \"JavaScript\": [\".js\", \".jsx\"],\n            \"TypeScript\": [\".ts\", \".tsx\"],\n            \"HTML\": [\".html\", \".htm\"],\n            \"CSS\": [\".css\", \".scss\", \".sass\", \".less\"],\n            \"Java\": [\".java\"],\n            \"C#\": [\".cs\"],\n            \"C/C++\": [\".c\", \".cpp\", \".h\", \".hpp\"],\n            \"Go\": [\".go\"],\n            \"Rust\": [\".rs\"],\n            \"PHP\": [\".php\"],\n            \"Ruby\": [\".rb\"],\n            \"Swift\": [\".swift\"],\n            \"Kotlin\": [\".kt\"],\n            \"Shell\": [\".sh\", \".bash\"],\n            \"PowerShell\": [\".ps1\"],\n            \"Markdown\": [\".md\"],\n            \"JSON\": [\".json\"],\n            \"YAML\": [\".yml\", \".yaml\"],\n            \"SQL\": [\".sql\"],\n        }\n",
    "summary": "The code defines a class for organizing and processing files in various programming languages within specified directories, excluding certain ignored paths.",
    "key_concepts": [
      "Initialization",
      "Output directory setup: `output_dir = \"00_docs\"`",
      "Ignored directories list creation: `.git`, `node_modules`, etc.",
      "Ignored files list definition: `.gitignore`, `.DS_Store`",
      "Text file extensions identification for various languages (Python, JavaScript, TypeScript, HTML, CSS, and others)",
      "Total files counter initialization",
      "Project root directory retrieval using os.getcwd()",
      "Git presence check with `_check_git()`",
      "KEY CONCEPTS/STEPS:",
      "Initialization of class/object attributes",
      "Directory exclusion lists setup: `ignore_dirs`, `ignore_files`",
      "Text file extensions for language detection compiled into a dictionary (`language_patterns`)",
      "Total files and text files counters initialized to zero"
    ],
    "tags": [
      "language detection",
      "os.getcwd()",
      "ignore_dirs",
      "language_patterns",
      "text_extensions",
      "project_root",
      "total_files",
      "gitignore files",
      "python patterns",
      "javascript patterns",
      "typecript patterns",
      "html patterns",
      "css patterns",
      "java patterns",
      "c++ patterns",
      "go patterns",
      "rust patterns",
      "php patterns",
      "ruby patterns",
      "swift patterns",
      "kotlin patterns",
      "shell patterns",
      "powershell patterns",
      "markdown patterns",
      "json patterns",
      "yaml patterns",
      "sql patterns"
    ],
    "sequence_index": 0,
    "parent_identifier": "CodebaseAnalyzer",
    "dependencies": [
      "os",
      "self._check_git",
      "Language detection patterns // Patrones de detección de lenguajes"
    ],
    "produced_outputs": [
      "self.output_dir",
      "self.ignore_dirs",
      "self.ignore_files",
      "self.text_extensions",
      "total_files",
      "total_text_files",
      "project_root",
      "has_git",
      "language_patterns"
    ],
    "follow_up_questions": [],
    "source": null
  },
  "file_codebase_analyzer_python_function_CodebaseAnalyzer__detect_file_language_9": {
    "id": "file_codebase_analyzer_python_function_CodebaseAnalyzer__detect_file_language_9",
    "raw": "    def _detect_file_language(self, file_path):\n        \"\"\"Detect programming language based on file extension. // Detectar el lenguaje de programación basado en la extensión del archivo.\"\"\"\n        _, ext = os.path.splitext(file_path.lower())\n        for lang, extensions in self.language_patterns.items():\n            if ext in extensions:\n                return lang\n        return \"Unknown\"\n",
    "summary": "The function detects the programming language of a file based on its extension.",
    "key_concepts": [
      "Detect programming language based on file extension",
      "File path manipulation using os.path.splitext()",
      "Lowercase conversion of the file path",
      "Iterating through a dictionary with extensions as keys and languages as values",
      "Returning detected language or \"Unknown\" if not matched"
    ],
    "tags": [
      "file detection",
      "programming language",
      "file extension",
      "os.path",
      "dictionary",
      "string manipulation",
      "pattern matching",
      "lowercasing",
      "function definition",
      "default value"
    ],
    "sequence_index": 8,
    "parent_identifier": "CodebaseAnalyzer",
    "dependencies": [
      "os.path",
      "self.language_patterns",
      "language_patterns"
    ],
    "produced_outputs": [
      "language",
      "self.language_patterns"
    ],
    "follow_up_questions": [],
    "source": null
  },
  "file_codebase_analyzer_python_function_CodebaseAnalyzer_create_output_dir_10": {
    "id": "file_codebase_analyzer_python_function_CodebaseAnalyzer_create_output_dir_10",
    "raw": "    def create_output_dir(self):\n        \"\"\"Create the output directory if it doesn't exist. // Crear el directorio de salida si no existe.\"\"\"\n        if not os.path.exists(self.output_dir):\n            os.makedirs(self.output_dir)\n            print(f\"Created output directory: {self.output_dir}\")\n",
    "summary": "The function creates an output directory for storing results, and prints a confirmation message upon creation.",
    "key_concepts": [
      "create_output_dir",
      "self.output_dir",
      "os.path.exists",
      "os.makedirs",
      "Print statement",
      "Output directory creation"
    ],
    "tags": [
      "os.path",
      "dir creation",
      "file handling",
      "python",
      "os module",
      "exception handling",
      "system interaction",
      "path checking"
    ],
    "sequence_index": 9,
    "parent_identifier": "CodebaseAnalyzer",
    "dependencies": [
      "os",
      "path_exists",
      "makedirs",
      "print"
    ],
    "produced_outputs": [
      "output_dir",
      "print"
    ],
    "follow_up_questions": [],
    "source": null
  },
  "file_codebase_analyzer_python_function_CodebaseAnalyzer_scan_codebase_11": {
    "id": "file_codebase_analyzer_python_function_CodebaseAnalyzer_scan_codebase_11",
    "raw": "    def scan_codebase(self):\n        \"\"\"Scan the codebase and gather information. // Escanear el código base y recopilar información.\"\"\"\n        self._print_status(\"Starting codebase analysis...\")\n        self.create_output_dir()\n        \n        all_files = []\n        language_stats = defaultdict(int)\n        dir_stats = defaultdict(lambda: {'files': 0, 'text_files': 0, 'lines': 0})\n        \n        # Walk through the codebase // Recorrer el código del proyecto\n        for root, dirs, files in os.walk('.'):\n            # Skip ignored directories // Omitir directorios ignorados\n            dirs[:] = [d for d in dirs if not self._should_ignore(os.path.join(root, d))]\n            \n            for file in files:\n                file_path = os.path.join(root, file)\n                if self._should_ignore(file_path):\n                    continue\n                \n                self.total_files += 1\n                \n                # Get file info // Obtener información del archivo\n                file_info = self._get_file_info(file_path)\n                all_files.append(file_info)\n                \n                if file_info['is_text']:\n                    self.total_text_files += 1\n                    language = self._detect_file_language(file_path)\n                    language_stats[language] += 1\n                \n                # Update directory stats // Actualizar estadísticas del directorio\n                rel_dir = os.path.dirname(file_info['path']) or '.'\n                dir_stats[rel_dir]['files'] += 1\n                if file_info['is_text']:\n                    dir_stats[rel_dir]['text_files'] += 1\n                    dir_stats[rel_dir]['lines'] += file_info['lines']\n                \n                # Show progress occasionally // Mostrar progreso ocasionalmente\n                if self.total_files % 100 == 0:\n                    self._print_progress(self.total_files, self.total_files, \n                                       'Scanning files', f\"({self.total_text_files} text files)\")\n        \n        # Final progress update // Actualización final de progreso\n        self._print_progress(self.total_files, self.total_files, \n                           'Scanning files', f\"({self.total_text_files} text files)\")\n        \n        # Generate the analysis files // Generar los archivos de análisis\n        self._generate_files(all_files, language_stats, dir_stats)\n",
    "summary": "The function scans a codebase to collect and analyze information about its structure.",
    "key_concepts": [
      "Scan codebase",
      "Gather information",
      "Starting status message",
      "Create output directory",
      "Walk through the codebase",
      "Skip ignored directories",
      "Get file info",
      "Detect file language",
      "Update statistics for files and text files in a directory",
      "Show progress occasionally",
      "Final progress update",
      "Generate analysis files"
    ],
    "tags": [
      "codebase scanning",
      "os.walk",
      "file_info",
      "directory statistics",
      "progress tracking",
      "ignored directories",
      "programming languages",
      "text detection",
      "output generation",
      "defaultdict",
      "lambda functions",
      "total files",
      "total lines",
      "scan analysis",
      "python code",
      "recursive traversal",
      "ignore patterns",
      "language identification",
      "data aggregation",
      "software development",
      "source control",
      "static analysis"
    ],
    "sequence_index": 10,
    "parent_identifier": "CodebaseAnalyzer",
    "dependencies": [
      "os.walk",
      "dirpath.join",
      "defaultdict",
      "print_progress",
      "get_file_info",
      "detect_file_language",
      "should_ignore",
      "is_text",
      "total_files",
      "total_text_files",
      "self.create_output_dir",
      "scan_codebase",
      "__main__.sysconfig"
    ],
    "produced_outputs": [
      "all_files",
      "language_stats",
      "dir_stats",
      "total_files",
      "total_text_files"
    ],
    "follow_up_questions": [],
    "source": null
  },
  "file_codebase_analyzer_python_function_CodebaseAnalyzer__get_git_info_12": {
    "id": "file_codebase_analyzer_python_function_CodebaseAnalyzer__get_git_info_12",
    "raw": "    def _get_git_info(self):\n        \"\"\"Get git repository information if available. // Obtener información del repositorio git si está disponible.\"\"\"\n        if not self.has_git:\n            return {\"available\": False}\n        \n        try:\n            # Get current branch // Obtener rama actual\n            branch = subprocess.check_output(\n                [\"git\", \"rev-parse\", \"--abbrev-ref\", \"HEAD\"], \n                stderr=subprocess.PIPE, text=True\n            ).strip()\n            \n            # Get last commit // Obtener último commit\n            last_commit = subprocess.check_output(\n                [\"git\", \"log\", \"-1\", \"--pretty=format:%h - %s (%cr)\"], \n                stderr=subprocess.PIPE, text=True\n            ).strip()\n            \n            # Count commits // Contar commits\n            commit_count = subprocess.check_output(\n                [\"git\", \"rev-list\", \"--count\", \"HEAD\"], \n                stderr=subprocess.PIPE, text=True\n            ).strip()\n            \n            # Get remote URL // Obtener URL remota\n            try:\n                remote_url = subprocess.check_output(\n                    [\"git\", \"config\", \"--get\", \"remote.origin.url\"], \n                    stderr=subprocess.PIPE, text=True\n                ).strip()\n            except subprocess.CalledProcessError:\n                remote_url = \"No remote URL configured\"\n            \n            return {\n                \"available\": True,\n                \"branch\": branch,\n                \"last_commit\": last_commit,\n                \"commit_count\": commit_count,\n                \"remote_url\": remote_url\n            }\n        except subprocess.SubprocessError:\n            return {\"available\": False}\n",
    "summary": "The function retrieves detailed information about a git repository, including the current branch and status.",
    "key_concepts": [
      "Git repository information retrieval",
      "Check if git is available: `self.has_git`",
      "Get current branch using `git rev-parse --abbrev-ref HEAD`",
      "Retrieve last commit with formatted output from `git log -1 --pretty=format:%h - %s (%cr)`",
      "Count commits via `git rev-list --count HEAD`",
      "Fetch remote URL through `git config --get remote.origin.url` or handle missing configuration",
      "Handle exceptions for subprocess errors and return appropriate status"
    ],
    "tags": [
      "subprocess",
      "git_info",
      "repository_details",
      "command_execution",
      "error_handling",
      "branch_name",
      "last_commit_hash",
      "commit_history",
      "remote_configuration",
      "python_code",
      "shell_commands",
      "version_control",
      "code_snippet",
      "software_development",
      "automation_script",
      "system_interaction",
      "programming_language",
      "development_tools",
      "technical_documentation"
    ],
    "sequence_index": 11,
    "parent_identifier": "CodebaseAnalyzer",
    "dependencies": [
      "subprocess",
      "self.has_git",
      "git",
      "stderr",
      "stdout",
      "text",
      "strip",
      "CalledProcessError",
      "RemoteOriginURLConfigGetter",
      "remote.origin.url",
      "origin",
      "GitRepositoryInfoRetriever",
      "HEAD",
      "rev-parse",
      "abbrev-ref",
      "log",
      "rev-list",
      "count",
      "config",
      "get",
      "url"
    ],
    "produced_outputs": [
      "Branch",
      "Last Commit",
      "Commit Count",
      "Remote URL"
    ],
    "follow_up_questions": [],
    "source": null
  },
  "file_codebase_analyzer_python_function_CodebaseAnalyzer__format_size_15": {
    "id": "file_codebase_analyzer_python_function_CodebaseAnalyzer__format_size_15",
    "raw": "    def _format_size(self, size_bytes):\n        \"\"\"Format file size in a readable format. // Formatear tamaño de archivo en un formato legible.\"\"\"\n        for unit in ['B', 'KB', 'MB', 'GB']:\n            if size_bytes < 1024 or unit == 'GB':\n                return f\"{size_bytes:.1f} {unit}\"\n            size_bytes /= 1024\n",
    "summary": "The function formats a given file size into the largest readable units (bytes, KB, MB, GB).",
    "key_concepts": [
      "_format_size function",
      "file size formatting",
      "readable format conversion",
      "units: B, KB, MB, GB",
      "threshold check for unit change",
      "division by 1024 to convert bytes",
      "formatted output with one decimal place"
    ],
    "tags": [
      "file_size_formatting",
      "python_function",
      "byte_conversion",
      "readable_output",
      "units_of_measurement",
      "binary_prefixes",
      "floating_point_representation"
    ],
    "sequence_index": 14,
    "parent_identifier": "CodebaseAnalyzer",
    "dependencies": [
      "`self.xyz`",
      "globals",
      "imports"
    ],
    "produced_outputs": [
      "self.xyz"
    ],
    "follow_up_questions": [],
    "source": null
  },
  "file_codebase_analyzer_python_function_CodebaseAnalyzer__generate_files_13": {
    "id": "file_codebase_analyzer_python_function_CodebaseAnalyzer__generate_files_13",
    "raw": "    def _generate_files(self, all_files, language_stats, dir_stats):\n        \"\"\"Generate all analysis files. // Generar todos los archivos de análisis.\"\"\"\n        self._print_status(\"Generating analysis files...\")\n        \n        # 1. Generate summary report // Generar informe de resumen\n        self._generate_summary(all_files, language_stats, dir_stats)\n        \n        # 2. Generate codebase structure // Generar estructura del código base\n        self._generate_structure(all_files)\n        \n        # 3. Generate largest files list // Generar lista de archivos más grandes\n        self._generate_largest_files(all_files)\n        \n        # 4. Generate recent files list // Generar lista de archivos recientes\n        self._generate_recent_files(all_files)\n        \n        # 5. Generate folder summary // Generar resumen de carpetas\n        self._generate_folder_summary(dir_stats)\n        \n        self._print_status(f\"Codebase analysis complete! Files saved to {self.output_dir}/ directory\")\n",
    "summary": "The function generates a comprehensive set of code and file-related reports for an analyzed project.",
    "key_concepts": [
      "_generate_files function",
      "summary report generation",
      "codebase structure generation",
      "largest files list creation",
      "recent files list compilation",
      "folder summary production",
      "output directory saving",
      "language statistics analysis",
      "directory statistics analysis",
      "KEY ARGUMENTS/CLAIMS:",
      "None specified in the provided text/code snippet."
    ],
    "tags": [
      "file generation",
      "codebase structure",
      "file statistics",
      "recent files list",
      "summary report",
      "folder summary",
      "output_directory",
      "language_analysis",
      "python_code",
      "data_processing",
      "software_development",
      "programming_language_stats",
      "large_file_identification",
      "latest_files_tracking",
      "structured_data_output",
      "directory_statistics",
      "analysis_completion",
      "automated_scripting",
      "coding_tools"
    ],
    "sequence_index": 12,
    "parent_identifier": "CodebaseAnalyzer",
    "dependencies": [
      "all_files",
      "language_stats",
      "dir_stats",
      "output_dir"
    ],
    "produced_outputs": [
      "all_files language_stats dir_stats output_dir summary report structure code_base largest_files recent_files folder_summary"
    ],
    "follow_up_questions": [],
    "source": null
  },
  "file_codebase_analyzer_python_function_CodebaseAnalyzer__generate_summary_14": {
    "id": "file_codebase_analyzer_python_function_CodebaseAnalyzer__generate_summary_14",
    "raw": "    def _generate_summary(self, all_files, language_stats, dir_stats):\n        \"\"\"Generate a summary markdown file with project overview. // Generar un archivo markdown de resumen con la visión general del proyecto.\"\"\"\n        self._print_status(\"Generating project summary...\")\n        \n        git_info = self._get_git_info()\n        \n        with open(os.path.join(self.output_dir, 'project_summary.md'), 'w', encoding='utf-8') as f:\n            # Header // Encabezado\n            f.write(f\"# Project Summary\\n\\n\")\n            f.write(f\"Analysis generated on: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n            \n            # Git information // Información de Git\n            f.write(\"## Repository Information\\n\\n\")\n            if git_info[\"available\"]:\n                f.write(f\"- **Branch:** {git_info['branch']}\\n\")\n                f.write(f\"- **Latest Commit:** {git_info['last_commit']}\\n\")\n                f.write(f\"- **Commit Count:** {git_info['commit_count']}\\n\")\n                f.write(f\"- **Remote URL:** {git_info['remote_url']}\\n\")\n            else:\n                f.write(\"- Git information not available\\n\")\n            f.write(\"\\n\")\n            \n            # Overall statistics // Estadísticas generales\n            f.write(\"## Codebase Statistics\\n\\n\")\n            f.write(f\"- **Total Files:** {self.total_files:,}\\n\")\n            f.write(f\"- **Text Files:** {self.total_text_files:,}\\n\")\n            \n            # Calculate total lines // Calcular líneas totales\n            total_lines = sum(file_info['lines'] for file_info in all_files if file_info['is_text'])\n            f.write(f\"- **Total Lines of Code:** {total_lines:,}\\n\")\n            \n            # Calculate total size // Calcular tamaño total\n            total_size = sum(file_info['size'] for file_info in all_files)\n            f.write(f\"- **Total Size:** {self._format_size(total_size)}\\n\\n\")\n            \n            # Language statistics // Estadísticas de lenguajes\n            f.write(\"## Language Distribution\\n\\n\")\n            f.write(\"| Language | Files | % of Codebase |\\n\")\n            f.write(\"|----------|-------|---------------|\\n\")\n            \n            sorted_languages = sorted(language_stats.items(), key=lambda x: x[1], reverse=True)\n            for language, count in sorted_languages:\n                percentage = (count / self.total_text_files) * 100 if self.total_text_files > 0 else 0\n                f.write(f\"| {language} | {count:,} | {percentage:.1f}% |\\n\")\n            \n            f.write(\"\\n\")\n            \n            # Directory statistics // Estadísticas de directorios\n            f.write(\"## Top Directories\\n\\n\")\n            f.write(\"| Directory | Files | Text Files | Lines of Code |\\n\")\n            f.write(\"|-----------|-------|------------|---------------|\\n\")\n            \n            # Get the top 10 directories by file count // Obtener los 10 directorios principales por cantidad de archivos\n            sorted_dirs = sorted(dir_stats.items(), key=lambda x: x[1]['files'], reverse=True)[:10]\n            for dir_name, stats in sorted_dirs:\n                f.write(f\"| {dir_name} | {stats['files']:,} | {stats['text_files']:,} | {stats['lines']:,} |\\n\")\n                \n            f.write(\"\\n\")\n            \n            # Generated files // [Archivos generados]\n            f.write(\"## Generated Analysis Files\\n\\n\")\n            f.write(\"The following files have been generated in the `00_docs` directory:\\n\\n\")\n            f.write(\"- **project_summary.md**: This summary file\\n\")\n            f.write(\"- **codebase_structure.txt**: Complete listing of project files\\n\")\n            f.write(\"- **largest_files.txt**: Top 20 files by line count\\n\")\n            f.write(\"- **recent_files.txt**: 20 most recently modified files\\n\")\n            f.write(\"- **folder_summary.txt**: Detailed folder statistics\\n\")\n",
    "summary": "The function generates a comprehensive markdown summary file detailing project overview, including git information and codebase analytics.",
    "key_concepts": [
      "Project summary generation",
      "Git information retrieval",
      "File path joining and writing to markdown file",
      "Header creation for Markdown document",
      "Current date-time formatting",
      "Repository branch details",
      "Remote URL inclusion",
      "Total files count display",
      "Text files differentiation from total files",
      "Lines of code calculation across text files",
      "Size summation in bytes (formatting function)",
      "Language distribution statistics and sorting by file counts per language",
      "Top directories listing based on number of contained files",
      "Generated analysis files documentation"
    ],
    "tags": [
      "file generation",
      "markdown creation",
      "git repository analysis",
      "codebase metrics",
      "language distribution",
      "directory structure",
      "project overview summary",
      "file size calculation",
      "text processing",
      "datetime formatting."
    ],
    "sequence_index": 13,
    "parent_identifier": "CodebaseAnalyzer",
    "dependencies": [
      "all_files",
      "language_stats",
      "dir_stats",
      "self.output_dir",
      "datetime.datetime.now()",
      "os.path.join",
      "sum",
      "sorted",
      "format_size",
      "strftime"
    ],
    "produced_outputs": [
      "self.total_lines",
      "self._format_size(total_size)",
      "self.output_dir",
      "dir_stats",
      "language_stats",
      "sorted_languages",
      "total_text_files",
      "sorted_dirs",
      "git_info",
      "all_files"
    ],
    "follow_up_questions": [],
    "source": null
  },
  "file_codebase_analyzer_python_function_CodebaseAnalyzer__generate_structure_16": {
    "id": "file_codebase_analyzer_python_function_CodebaseAnalyzer__generate_structure_16",
    "raw": "    def _generate_structure(self, all_files):\n        \"\"\"Generate file listing structure. // Generar estructura de listado de archivos.\"\"\"\n        self._print_status(\"Generating codebase structure...\")\n        \n        with open(os.path.join(self.output_dir, 'codebase_structure.txt'), 'w', encoding='utf-8') as f:\n            f.write(f\"# Codebase Structure ({self.total_files:,} files)\\n\")\n            f.write(f\"# Generated: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n            \n            for file_info in sorted(all_files, key=lambda x: x['path']):\n                f.write(f\"{file_info['path']}\\n\")\n",
    "summary": "The function generates a text listing of all files within the codebase.",
    "key_concepts": [
      "_generate_structure",
      "all_files structure generation",
      "output_dir path joining",
      "codebase_structure.txt file writing",
      "sorted files by 'path",
      "datetime.now() timestamping",
      "TEXT/CODE SNIPPET:",
      "def generate_code(self, language='python'):",
      "\"\"Generate a simple template for the specified programming language.\"\"",
      "templates = {",
      "python': \"def main():\\n\\t# TODO: Implement this function\\n\",",
      "java': \"public class Main {\\n\\t// TODO: implement methods here\\n}\\n",
      "}",
      "code_template = templates.get(language, \"\")",
      "if not code_template:",
      "raise ValueError(f\"No template available for language '{language}'\")",
      "return code_template",
      "KEY CONCEPTS/STEPS (one item per line, keywords/short phrases ONLY):",
      "generate_code function",
      "default parameter 'python",
      "dictionary of templates by programming languages ('python', 'java')",
      "error handling with raise ValueError",
      "template retrieval using get method"
    ],
    "tags": [
      "file structure generation",
      "codebase",
      "output directory",
      "sorting files",
      "writing to text",
      "utf-8 encoding",
      "datetime formatting",
      "file paths"
    ],
    "sequence_index": 15,
    "parent_identifier": "CodebaseAnalyzer",
    "dependencies": [
      "os",
      "datetime",
      "self.output_dir",
      "self.total_files"
    ],
    "produced_outputs": [
      "self.output_dir",
      "self.total_files"
    ],
    "follow_up_questions": [],
    "source": null
  },
  "file_codebase_analyzer_python_function_CodebaseAnalyzer__generate_folder_summary_19": {
    "id": "file_codebase_analyzer_python_function_CodebaseAnalyzer__generate_folder_summary_19",
    "raw": "    def _generate_folder_summary(self, dir_stats):\n        \"\"\"Generate folder summary statistics. // Generar estadísticas resumidas de carpetas.\"\"\"\n        self._print_status(\"Generating folder summary...\")\n        \n        # Sort directories by file count // [Ordenar directorios por cantidad de archivos]\n        sorted_dirs = sorted(dir_stats.items(), key=lambda x: x[1]['files'], reverse=True)\n        \n        with open(os.path.join(self.output_dir, 'folder_summary.txt'), 'w', encoding='utf-8') as f:\n            f.write(\"# Folder Summary\\n\")\n            f.write(f\"# Generated: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n            f.write(\"Directory                      | Files  | Text Files | Lines of Code\\n\")\n            f.write(\"-------------------------------|--------|------------|-------------\\n\")\n            \n            for dir_name, stats in sorted_dirs:\n                # Truncate long directory names // [Truncar nombres de directorios largos]\n                display_name = dir_name\n                if len(display_name) > 30:\n                    display_name = display_name[:27] + \"...\"\n                    \n                f.write(f\"{display_name:30} | {stats['files']:6,} | {stats['text_files']:10,} | {stats['lines']:13,}\\n\")\n",
    "summary": "The function generates a summary of folder statistics sorted by file count.",
    "key_concepts": [
      "Generate folder summary",
      "Sort directories by file count",
      "Open output file for writing",
      "Write header and timestamp to the file",
      "Loop through sorted directory statistics",
      "Truncate long directory names",
      "Format and write each entry's details into the file",
      "KEY CONCEPTS/STEPS (one item per line, keywords/short phrases ONLY):",
      "Generate folder summary",
      "Sort directories by file count",
      "Open output file for writing",
      "Write header to file",
      "Loop through stats",
      "Truncate long dir names",
      "Format directory entries"
    ],
    "tags": [
      "file sorting",
      "directory statistics",
      "file count",
      "text files",
      "lines of code",
      "output generation",
      "unicode encoding",
      "datetime formatting",
      "string truncation"
    ],
    "sequence_index": 18,
    "parent_identifier": "CodebaseAnalyzer",
    "dependencies": [
      "self.output_dir",
      "os.path.join",
      "datetime.datetime.now",
      "sorted",
      "open",
      "f.write"
    ],
    "produced_outputs": [
      "self.output_dir",
      "sorted_dirs",
      "dir_stats",
      "datetime.datetime.now()",
      "display_name"
    ],
    "follow_up_questions": [],
    "source": null
  },
  "file_codebase_analyzer_python_function_CodebaseAnalyzer__generate_largest_files_17": {
    "id": "file_codebase_analyzer_python_function_CodebaseAnalyzer__generate_largest_files_17",
    "raw": "    def _generate_largest_files(self, all_files):\n        \"\"\"Generate list of largest files by line count. // Generar lista de archivos más grandes por cantidad de líneas.\"\"\"\n        self._print_status(\"Generating largest files listing...\")\n        \n        # Filter text files and sort by line count // Filtrar archivos de texto y ordenar por cantidad de líneas\n        text_files = [f for f in all_files if f['is_text']]\n        largest_files = sorted(text_files, key=lambda x: x['lines'], reverse=True)[:20]\n        \n        with open(os.path.join(self.output_dir, 'largest_files.txt'), 'w', encoding='utf-8') as f:\n            f.write(\"# 20 Largest Files by Line Count\\n\")\n            f.write(f\"# Generated: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n            f.write(\"Lines    | Size       | Language   | File Path\\n\")\n            f.write(\"---------|------------|------------|----------\\n\")\n            \n            for file_info in largest_files:\n                language = self._detect_file_language(file_info['path'])\n                f.write(f\"{file_info['lines']:8,} | {self._format_size(file_info['size']):10} | {language:10} | {file_info['path']}\\n\")\n",
    "summary": "The function generates a list of the 20 largest text files by line count and saves it to 'largest_files.txt' with details.",
    "key_concepts": [
      "_generate_largest_files",
      "largest files by line count",
      "Generar lista de archivos más grandes por cantidad de líneas",
      "Filter text files",
      "Sort by line count",
      "Open file for writing",
      "Write header and timestamp",
      "Detect language",
      "Format size",
      "KEY CONCEPTS/STEPS (one item per line, keywords/short phrases ONLY):",
      "_generate_largest_files",
      "largest files by line count",
      "Generar lista de archivos más grandes por cantidad de líneas",
      "Filter text files",
      "Sort by line count",
      "Open file for writing",
      "Write header and timestamp",
      "Detect language",
      "Format size"
    ],
    "tags": [
      "text files",
      "sorting",
      "lambda function",
      "file path",
      "encoding",
      "datetime",
      "language detection",
      "output directory",
      "largest_files.txt",
      "utf-8",
      "_detect_file_language",
      "_format_size",
      "os.path.join",
      "write to file",
      "list comprehension",
      "reverse order",
      "filter by is_text",
      "generate status message",
      "line count"
    ],
    "sequence_index": 16,
    "parent_identifier": "CodebaseAnalyzer",
    "dependencies": [
      "all_files",
      "output_dir",
      "datetime.datetime.now()"
    ],
    "produced_outputs": [
      "largest_files",
      "output_dir",
      "datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')",
      "lines    | Size       | Language   | File Path"
    ],
    "follow_up_questions": [],
    "source": null
  },
  "file_codebase_analyzer_python_function_CodebaseAnalyzer__generate_recent_files_18": {
    "id": "file_codebase_analyzer_python_function_CodebaseAnalyzer__generate_recent_files_18",
    "raw": "    def _generate_recent_files(self, all_files):\n        \"\"\"Generate list of recently modified files. // Generar lista de archivos modificados recientemente.\"\"\"\n        self._print_status(\"Generating recently modified files listing...\")\n        \n        recent_files = sorted(all_files, key=lambda x: x['mtime'], reverse=True)[:20]\n        \n        with open(os.path.join(self.output_dir, 'recent_files.txt'), 'w', encoding='utf-8') as f:\n            f.write(\"# 20 Most Recently Modified Files\\n\")\n            f.write(f\"# Generated: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n            f.write(\"Last Modified        | Language   | File Path\\n\")\n            f.write(\"--------------------|------------|----------\\n\")\n            \n            for file_info in recent_files:\n                modified = datetime.datetime.fromtimestamp(file_info['mtime']).strftime('%Y-%m-%d %H:%M:%S')\n                language = self._detect_file_language(file_info['path'])\n                f.write(f\"{modified} | {language:10} | {file_info['path']}\\n\")\n",
    "summary": "The function generates and saves a list of the 20 most recently modified files with their modification dates, languages detected from file paths, to 'recent_files.txt' in an output directory.",
    "key_concepts": [
      "_generate_recent_files",
      "recently modified files listing",
      "sorted by modification time",
      "top 20 results",
      "output directory path construction",
      "writing to text file",
      "timestamp generation",
      "language detection",
      "formatted table output",
      "KEY CONCEPTS/STEPS (one item per line, keywords/short phrases ONLY):",
      "_generate_recent_files function definition",
      "sorting files by 'mtime",
      "limit top 20 results",
      "open recent_files.txt for writing",
      "write headers to file",
      "iterate over sorted files list",
      "convert modification time to string format",
      "detect language of each file path",
      "output formatted table with last modified date, detected language, and full file path"
    ],
    "tags": [
      "file handling",
      "sorting",
      "datetime",
      "os.path.join",
      "file modification time",
      "recent files generation",
      "language detection",
      "output directory",
      "text writing",
      "encoding",
      "timestamp formatting"
    ],
    "sequence_index": 17,
    "parent_identifier": "CodebaseAnalyzer",
    "dependencies": [
      "os",
      "datetime",
      "self.output_dir",
      "self._print_status",
      "self._detect_file_language"
    ],
    "produced_outputs": [
      "recent_files",
      "self.output_dir",
      "datetime.datetime.now()",
      "datetime.datetime.fromtimestamp()"
    ],
    "follow_up_questions": [],
    "source": null
  },
  "file_codebase_analyzer_python_function_main_20": {
    "id": "file_codebase_analyzer_python_function_main_20",
    "raw": "def main():\n    analyzer = CodebaseAnalyzer()\n    analyzer.scan_codebase()\n",
    "summary": "The code defines and executes an analysis of a software project's source files.",
    "key_concepts": [
      "Main function definition",
      "Class instantiation: `CodebaseAnalyzer`",
      "Method call on object instance: `.scan_codebase()`",
      "TEXT/CODE SNIPPET:",
      "```python",
      "def main():",
      "analyzer = CodebaseAnalyzer()",
      "analyzer.scan_codebase()",
      "class CodebaseAnalyzer:",
      "def scan_codebase(self):",
      "# Scan the code for patterns, functions and classes.",
      "pass",
      "if __name__ == \"__main__\":",
      "main()",
      "```",
      "KEY CONCEPTS/STEPS (one item per line, keywords/short phrases ONLY):",
      "Main function definition",
      "Class instantiation: `CodebaseAnalyzer`",
      "Method call on object instance: `.scan_codebase()`",
      "Conditional execution check: `if __name__ == \"__main__\":`",
      "Entry point of the script: `main()`"
    ],
    "tags": [
      "code analysis",
      "software development",
      "python programming",
      "code scanning",
      "static analysis",
      "automated testing",
      "source control integration"
    ],
    "sequence_index": 19,
    "parent_identifier": "codebase_analyzer",
    "dependencies": [
      "CodebaseAnalyzer",
      "scan_codebase"
    ],
    "produced_outputs": [],
    "follow_up_questions": [],
    "source": null
  }
}